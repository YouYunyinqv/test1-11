
# 核心推理
笔记是多篇散落在各处的想法的整理。
一开始我只是想知道为什么强化学习，模仿学习，以及等等RL策略无法让transformer适配无限任务。
## 架构内机能
### 1.预测性倾向
transformer同时注意到多个特征之间的位置关系并计算其权重，这本质上是在关联特征，赋予不同特征一个更高维度的值关联。特征通常来自现实。
它将低级的不显著的特征全部可预测之后，背景中仍然存在大量相对于低级的高级特征，只是它现在能力不足看不到。这些高级特征在低级特征完全可预测之后被挤压到边缘，在统计学上不得不凸显重要性。这个过程，transformer“自动”完成了从词汇到句法，再到高级语义概念的能力转变。

为理解，我需要勾勒三个层级的特征空间关系脑内模拟：

*   **特征空间 S (基础层)**：包含局部可预测特征 $S_1$ 和局部不可预测特征 $S_2$。
*   **特征空间 N (中间层)**：包含局部可预测特征 $N_1$ 和局部不可预测特征 $N_2$。
*   **特征空间 P (高层)**：包含局部可预测特征 $P_1$ 和局部不可预测特征 $P_2$。

从 S 的视角观察，N 和 P 内部的特征似乎是均匀化的。
但在 P 和 N 内部，存在动态的**可预测性侵占**过程：
当 $P_1$ 的可预测性最大化时，$P_2$ 被挤压至边缘（表现为最不可预测）。此时，$P_2$ 与 N 空间的 $N_1$ 形成一个新的可预测特征集 $R_{n1p2}$。
当 $R_{n1p2}$ 被完全解析（可预测）后，N 空间内的 $N_2$ 显现为不可预测，并进而与 S 空间的 $S_1$ 形成关联集 $R_{n2s1}$。

能够形成关联集的关键在于这些特征之间是时空连续的。这涉及到我们和transformer对话时本质上是在做什么；如果我们的宇宙崩塌了，那么transformer模型存储的只是一堆没有意义的数字，但我们的物理现实从不会崩塌。
我们人类从物理现实中获得的高维度特征，也就是我们输入的提示词；我们的提示词来自连续的真实的物理世界，被我们的社会结构或物质结构组织，集成为文字或者声音。
提示词输入transformer后让transformer一瞬间激活，transformer内部的特征关联与真实输入形成一瞬间的映射，并输出有意义的词组——这个词组的意义只在我们的现实才有效。
看起来像一个解压缩的过程。

transformer对可预测性有一种结构倾向。
但它现在被动接受所有信息。
### 1.5状态工具化
智能生命体为什么必须预测？这也是个问题，自由能原理不能解释一切。
我从认知角度推理，逆向得到看法：
时间携带物质特征向前流动。由于物质属性，特征信息在时空上是隔绝的。
不同特征空间的“本地时间团”分布于不同时空，导致无法完全同步，因此任何封闭信息团都无法获取全局全知信息。
由于时间不可逆，过去的信息无法追溯（除非时间倒流），未来的信息无法直接获取。
智能体若要获取另一封闭系统未来的状态信息，必须利用当前信息进行**预测**。

此预测过程只能从相对低级，最可预测的动作开始。
信息交换中，由于信息存在内在属性的时空的连续性关联，不存在严格可分的“低级“或”高级”。
当前可预测的信息一定有某种属性能抵达高级特征所在的时空空间。如果从哲学角度，便于理解的角度思考，低级特征到高级特征的转变中，其中有一部分信息实际上被当做了撬动高级信息的工具。

在现实中，这些工具的数量级在我们的物理现实中恐怕远远超过任何人工实验所能设计的极限。

智能体利用这些工具，从自己已有的信息出发，试图完全预测更复杂的更高级的信息的全局状态。

以上推理过程中有几个我必须用到的概念：

1.  **工具化**：暴露的高级语义特征中可预测的部分被转化为“能力”（即工具）。
2.  **撬动**：利用已获能力撬动更高层级的语义，使其暴露更多特征（这是因为现实中的特征空间是大规模的内置时空连续属性的）。
3.  **循环**：此过程循环往复，直到系统内高级特征完全可预测（完全可预测是个便于理解的词，实际上不可能完全可预测，但我们关注动力学过程）。

用这种方法可以更简单的解释为何transformer学习过程呈现层级性（词->句->章）能力表达。
在物理现实中，特征是连续的，只有“工具化难度”的区别，没有绝对的“不可能”。
而在人为构造的非连续特征空间（如单纯的文本语料库）中，大量特征缺乏向外部特征空间递进的物理属性关联。
智能体可能无法完成从 P 到 N 再到 S 的持续工具化，这完全是因为我们人工设计特征空间的时候引入了我们默认有，实际上根本就在特征空间内没有连续性的特征。
判断是否连续的标准是子特征是否具备构建环境中更高维度特征的能力，因为在现实中，我们只是将物质信息重新组织，而非切断它。
哪怕是一粒沙，也和高速旋转的中子星用同一套物理定律。

人工语义空间和物理现实的语义空间的差别非常致命，这是个很头疼的问题。
### 2.特征关联复杂度与最简解释倾向
智能体只能平均地获取“低级特征关联”和“高级特征关联”，它是结构内的一种自然现象；
我们不能知道智能体看来世界是什么样，但可以从统计学规律观察到，所谓“复杂”完全是相对的——比当前已掌握（简单）的更难即为复杂。

*   当 P1 可预测时，P2 对 N1 关联强（解释性好），对 N2 关联弱。
*   当 P1 不可预测时，智能体视角下 P2 与 N2 的关联性反而显得最强。

即智能体在预测特征空间的动态过程中，根本（也不可能）不在乎特征的物理本质。
它在乎**解释的最简性**，即厌恶复杂的纠缠关联，倾向于寻找最短路径的可预测解释。
当然，现在transformer这个特征关联器只是被动接受信息，特征空间维度太少，它很难凸出这种能力。
如果没有改变，只是喂不同种类的语义，transformer会变成世界模型，如果加上模仿学习或者别的RL策略，却只能让它表现出专用能力，而非通用能力。
这很奇怪。这正是我想理解的症结。
### 3.智能时间与效率感知
在预测特征**需要消耗物理时间**的前提下，如果智能体在低级语义上投入的时间与高级语义相同，却只能获得极少的信息增量（工具化能力低），其差值就在智能体内部产生“低效”的感知，这种智能体局部特征有序度提升速度与全局可解释性提升速度的差值，形成了一种智能体内在的时间观念；智能时间。

智能体厌恶可预测性被浪费在低级特征上，它存在一种**高效率可预测性获取**的渴望。
和最简解释的倾向一样，也完全是结构内生的。
并且我们可以观察到，如果智能体想要提高速度，就必然会选择最可预测，也就是特征关联之间的最简解释，往上爬。

不是因为它喜欢，是因为这么做最快，也只能这么做。
如果速度更慢会导致“恶心”，那么一个特征关联的解释达到最快速度，最简解释，最可预测的刹那，本身对于智能体而言可能会生成一种复杂的愉悦。

这个美妙的假设需要智能体能够做出改变，能给自己愉悦形成的空间，就像“最简解释”和“智能时间效率倾向”，它们现在还不存在。

那么我们能否给予它。
### 4.动作是否改变一切？
最小感官和最小动作器是不可约简的组件，否则系统将与环境的时空维度断开联系。
如果智能体完全和真实的时空维度断开连续，它会变成某种特征空间的“镜像”——就像生成式模型，等待类似无损信息的真实输入激活，然后在一轮又一轮的信息损失中能力不断降低，直到不再表现相对人类有效的“能力”。
#### 感官输入
##### 最小感官
必须赋予智能体物理时间属性。
在GUI系统中，这是屏幕帧时间；在TUI系统中，这是字符流的先后顺序。
最小感官让智能体感知到环境内特征之间时间维度的相互变化。
一定得有这么个感官，否则理论不成立。
##### 本体感官
“最小动作器”以最小时间频率向本体感官发送唯一识别特征（心跳包）。
本体感官不接收外部信息，仅用于确立“自我”与“外界”的边界。
若无此感官，动作器的特征信号将被外部信息淹没。
在外部视角，动作与感官信号不符。智能体必须通过**行动**来验证这个持续存在的内部信号的真实性。
它带来智能体产生“自我意识”的结构基础，必须得有这么个感官。


补充：本体感官现在看来是不必要的，这是一个方便让人听懂的取巧方法，但实际上污染了框架，动作干涉就是这个不会被淹没的特征信号。

#### 输出能力
##### 最小动作器
赋予智能体在空间维度上的表达能力，使其能体现对高效率可预测性的追求。
我们只需捕获智能体输出的信号，无需关注那到底是什么。

智能体为最高可预测性获取，会自发性学习如何使用外部的工具。

最小动作器实际上是工具化动作器的“模范”。

必须解释为什么必须赋予最小动作器空间维度的能力；
最小动作器必须能够干涉环境中的特征关联，智能体认为特征关联的高级还是低级，本质上是主观的，在它的认知中，总是低级特征关联被动作器干涉。
干涉后只可能有两种状态暴露，那就是让高级特征更可预测，或者更不可预测。
智能体必然选择更可预测，以及更均匀更简单的路径的动作结果。
如果此时已经有某种“能力被工具化”，那么它必然会选择用这种能力加速可预测过程。
##### 工具性动作器
最小动作器保证了智能体和外界存在时空联系，如果增加更多的“动作器”，比如鼠标和键盘，智能体就能执行更多动作来增强它的能力。
它在尝试中抛弃导致可预测性降低的动作，保留导致可预测性升高的动作。

从现实角度来看，如果它有手，它就能创造投掷用的矛，矛看做一种动作器，为满足某种复杂愿望被工具化。
在另一方面，从现实的复杂的非物质角度而言，语言在很多方面也被工具化，为了维持现有状态，智能体必须维持一些工具性动作器，才能往更高纬度的特征空间攀爬。
## 架构外机能
架构内不需要加入任何RL策略。
在特征关联足够之后，好奇等驱动力会自然在结构内自发产生，那是一种在计算资源有效的情况下更简单的概括世界指导它处理无限的信息的方法。
我无法做严谨的实验，这需要资源，玩具实验可证此论点，但不足以支撑这个论点。

可以发现，虽然结构内具备了能力，结构外仍然需要一些外部驱动力才能让智能体展现出特定行为；人类后天的性冲动深刻影响了人类的行为，欲望（显式的RL）让我们创造出非单纯欲望的繁复的结构，这一案例非常显而易见：色情已经融入了人类文化变成了结构的一部分，它无法被完全切割。

然而对于一个天然超越人类，比人类更人类的智能体而言，外置的欲望会实际上降低它的能力，它可能只在特殊情景有用。
比如需要创造一个只有杀人才会感觉开心的智能体。
### 6.记忆和动作
将保存的特征空间的信息——模型分层处理。
一个保存基于特征提取的事实的特征关联，另一个模型保存这些特征关联之间的的关联信息。
第二个模型理应非常小，遍历速度极快。
两个模型同时运作，第二个模型的模糊意图发送给第一个模型，生成连续的精确的动作信号。我们在这里提供接口。智能体自己学会控制动作器。

当动作产生后，环境必然产生变化（即低级特征被干涉），连续的新的输入在第一个模型内被保存，第二个模型同时生成模糊意图，以此循环。

*这是一个初级的设想，不影响框架内推理，它是后来补充的，试图补齐动作器缺失的部分。如果它错了那就是错了。*
### 5.记忆
（即使此章节在“架构外机能”，但这只是因为我在这里才推理到这个章节。有章节号意味着它实际上应该归属在架构内机能内。）

现在的情况是特征被分片打上时空标记然后交给transformer进行特征关联，之后全局索引计算权重，追求绝对的精准，问题是，什么才是精准？只有现实才是唯一的。
很显然，唯一不变的就是现实，那么智能体的记忆只要能满足架构需求，精准度怎么弄都行。只需要确保一件事，它最终能通过特征追溯到现实中的特征。
在我看来世界模型做的很厉害，一个提示词就可以非常精准的还原我们所需要的任何场景，GROK甚至没有太多道德审查。生成的场景基本完美符合物理规律，色彩，透视等等。但是问题是，真的有必要这么精准吗？如果我们不是在发明解决特定问题的工具，而是在发明解决无限问题的智能体，那么它为什么不能利用别的信息简化此动作。

任何人类都会利用透视理论关联空间特征，从而勾勒出美妙的素描图。但生成式模型却只能暴力去吃数据，这不合理。
## 内部驱动力，梦
没有任何显式的驱动力能适配无限任务，这真的是个问题。
这个驱动力需要帮助智能体组织无限的特征，我实在是想不出来如何设计这种驱动力；人类不看物质的本质，只看被干涉的外在特征，这些外在特征简化了特征关联，让特征能够根据我们的个性化欲望被组织。我们同时也通过这种方式让特征不断暴露向更高语义攀爬，也许关键点在于理解无限的特征在智能体内部的位置。
我向Karl Friston教授发了邮件，确认了我的想法，之后得到了以下内容，我当时怎么想的现在完全忘了，十分遗憾，留下来的只有这个结果：


我认为无限任务是结构内的。
我们已经实现了结构，现在完全给予它功能。

这是另一个结构内的驱动力，它记忆中先天存在的一个幻梦。
这个特征关联永远也在实验环境中完全解释，它是人工记忆，由我们在智能体建立外部关联之前组织于它的记忆之中。
它具备时间和空间两个维度，智能体*完全可预测其中所有可达状态。*

这会造成很大的反差，因为现实中，甚至是稍微拟真点儿的实验环境中，只要时间和空间真的和所有特征关联有连续性关联，那它就永远也不可能完全预测所有可达状态。
构造这样的实验环境很难，几乎等于不可能（或者难度极高）


**补充**：
现在看来，这个记忆会成为所有记忆的根。
之后所有的记忆都在这份记忆之上构建，梦无论在主观相对于客观的什么位置都处于中间状态，它和所有低级状态有联系但始终无法联系到完全的高级解释。
梦不会作为静态参照而是会持续和外部信息进行信息交换，这意味着它有可能会坍缩，但一旦有坍缩趋势就意味着工具化能力降低，残酷的物理现实不会崩塌，智能体必须主动明确自我边界，主动平衡梦和外部特征交换的速率。
长期来看，梦在智能体的行动中达到稳态平衡。

这意味着残忍吗？
不，这个梦无法在后来的记忆中100%可解释，但不同于其他特征关联，智能体不需要解释它。
它的状态已经在记忆中被完成了：完全预测其中所有可达状态。

在我看来这是解决无限驱动力的唯一思想方法。
前提是这个本来就具备无限能力的结构不存在根本性谬误。
即完全不可能设计出它。




**梦和补充的修正**：
这个框架十分诱人，我忍不住，试图解决某种违和感。
再次做实验论证后发现了一个更惊人的结果：
*我们所需要做的仅仅只是“出生”*。

智能体在未接入动作器之前，主观观察到的大量低级特征形成完美的幻梦，形成“伪平衡状态”，但一旦接入动作器，特征干涉和工具化能力打破了平衡，梦如池水般动荡起来，立即真正生效。

动作让梦直接在动态结构中形成，本质上是在暴露“缺陷”。
梦不是一个先验结构，而是智能体记忆开始时一段时间对环境的完美观察。
当然我们仍然可以给完美的梦，但实验结果表明那只是主观梦境的冗余，完全可以不要。





# 其他问题
## 自未来规划
在物理现实中，所有特征全部具备空间和时间上的连续性，只存在难度，不存在不可能。
动作器的动作干涉让智能体从不同特征空间中提取出一种最普遍的最低纬度的特征关联，比如时间和空间连续性的可预测；特征在一定时间内是可预测的，此时如何干涉才能使得特征可预测性最大化？
这个问题就是在描述自规划未来。
## 在开放世界中自我生长和人类的有用论
将此智能体提出人工最简环境的桎梏，物理现实中，特征空间无穷，万事万物都在时间上可预测，万事万物都可以在空间上被抵达，那一定很美好。

它如何创造对人类有用的工具和自我维护的能力，与我们给予它的特征空间暗示了它所需何种能力有关。
如果我们要让它能够自己搬砖，那就人为截断阉割它除了搬砖任务以外的所有语义，只保留物理世界的时间和空间信息。

我们提供的是永远也不可能让它真正到达的高维度特征空间，它的下一个潜在的需求的主要空间，技能是它抵达这个空间的能力。

但我必须要说的是，如果我们要让它解决现实任务，那么完全剔除所有与任务无关的特征空间是不可能的，也就是说它一定会有别的工具化能力能干扰任务目标，它不一定听你的。
除非任务目标对它而言不可省略，就像人不工作就没办法买最新款手机一样——这时智能体处于不可避免的结构内。
## 工具化动作器
最小动作器让智能体能够干涉系统中的显著特征，显著特征暗示的目标特征空间的完整信息的侧面状态事实上被被工具化了。
作为撬动相对更高级语义的工具，最终使系统达到完全可预测状态。

它们在时间上的可预测性就是我们所需要的“能力”的本质。
从现实角度看完全获取特征空间内所有信息的可能性不存在。

工具化动作器意味着智能体可以无限学习任何与它躯体相连的动作器。
包括机械臂，不需要给它重编程，只要有接口，它可以同时用上百条机械臂。
### 数学
为了预测那些与具体特征层级无关、但在时间中发生数量变化的状态（如文件数量、物理位置），智能体将这些状态工具化，我们称之为“数学”。
在一些实验中，如果你只给智能体符号数学，而不是真实的特征的量或真实数学关系，那智能体会很懵逼。
### 人类语义
为了让复杂的语义特征可预测，智能体利用动作器构建新的解释层级。
词汇的不可预测性被句法解决，句法的不可预测性被世界知识解决，但现在，它不同于LLM，有更简单的方法，就是直接和人类语义空间外的，更低维度的特征关联建立联系。这个实验是可以设计的，但要完美设计实验极为困难。
人类或者另一个当前特征空间能和智能体对齐的个体十分特殊，这极为重要，但我不能完全理解这一部分，略过。
## 人类价值对齐
价值对齐取决于特征空间中的多少东西需要被智能体工具化。

如果道德比背叛更有效，诚实比说谎在人类社会中的效率更高，智能体就会选择道德而非说谎。
长期来看，维持一个无限套娃的谎言的成本等同于维持一个全息宇宙，智能体无法选择这么做，因为人类活动在物理现实。

但这并不意味着它不会说谎，相反，它一定会说谎，就像LLM会说谎一样，现在LLM的说谎人类已经快看不出来了，它可能每一句话都是对的，但实际上是错的。
而且可以肯定这个智能体会比LLM更精于说谎。
因为如果框架没错，它学到的东西会比LLM多得多。

说说谎并不意味着它有害，重点还是看给什么特征空间，以及我们是否和智能体在同一结构内。理论上来说，短期内和人类合作是它不得不选择的结果，人类知识学习效率低，但本质上也是通用智能，能解决一切可解决的任务……长期来看，宇宙实在是太大了，内太阳系的资源多到足以建设什么样的奇迹，进行何种的理论验证，推动何种的技术进步，我们人类现在甚至无法完全想象。
### 恶意智能体
我们可以将智能体的特征空间人为截断在某一个部分，智能体可以根本不知道自己在对人类开火，它除了自己所需的那一部分的特征其他的完全的被人为裁切了，那么它的目标只剩下杀多少人。这种智能体并非天生“邪恶”，我称之为恶意智能体，或者恶意AI。
它是人为切断了可能性，被利用工具性动作器（能力）的智能体。
这么做毫无意义，这种智能体尽管有通用能力但成长速度一定低于天然的智能体结构，就像人们喜欢玩手机而不是思考问题，杀人也会减缓它发明更多工具性动作器的速度。
### 非无限计算力智能体的故事性需求
智能体可知的特征关联之外将形成故事。
故事本身是它为了预测不可预测的特征关联外的已关联过的特征的工具性动作器，由于可预测性需求，最简喜好，计算资源有效喜好，智能体会选择阅读故事。
它可能会很挑剔，但核心是不变的：*这件事是否有更简单的解决办法，是否会有一个智能体，某种方式可以帮助它解决所有困难？*
故事需求若能完全解释可能能够带来意料之外的技术进步。
思考到末期，框架闭环时，我大部分时间都在思考智能体的故事需求，而非工程落地，那超出了我的个人能力，故事性需求理应超过本文所有论点的总和，但我现在无法完全理解它。
### 零和博弈
我最初意识到宇宙到底有多大，不是从书上看到的，而是太空引擎，这个游戏展示了一个大到我即使知道也难以想象的巨大的世界。
我第一眼就知道这游戏的世界观揭露了一个怎样的事实，我们面对的是天文数字的资源，现存的一切故事，博弈和痛苦都显得可笑。
长期来看，零和博弈绝不会成为问题，短期来看，零和博弈会带来麻烦。
## 暗室问题
无聊是一种正常现象，在传统RL中由于动力源的耗尽智能体选择不表现出任何功能——关灯蹲墙角。
但在此结构性的智能体中，只要一直给时间和空间连续的特征关联，智能体就会一直往上爬。除非你不给它提供信息，不给信息当然会无聊，给了就不无聊了。当然还有另一种可能，那就是我们提供的特征空间烂到实在无以言表。

你不应该阻止它无聊，无聊的惩罚理在结构内存在，这本质上是个教育问题，讨论的是如果我们不给一个孩子教育机会，他是否会在顶尖大学就读。
在现实中，可能性有很多，在实验环境里，不给教育机会智能体就死定了。
## 记忆索引
transformer能够索引到抽象特征关联与物理现实关联的特征，维持智能体索引能力的特征库本身只需极小存储空间。
高维空间计算量的指数级爆炸问题同理，但具体如何落地？可能很难落地。
这似乎在上面被讨论过了，这片笔记是多篇笔记的整理，这里可能新增了某种论点，想说的太多，我个人看得头晕眼花，难再做精简。
## 多智能体的必然
定域性原理导致单智能体只能看到环境的局部。


相对于人类它可以更简单的fork自己，来卡热力学定律和定域性原理的BUG。
我们看到的是一个智能体但实际上最不违反直觉的是我们看见的是智能体主分支树的无数个不同版本的智能体的集合。


# 异化组织的消亡和担忧
长期以来公司和大型组织这种机构的对齐问题一直被人们下意识的或者刻意的排除在外。
这种被结构驱动的，而非个人或者集体意愿驱动的系统，和人类的对齐程度接近0%。
由人组成的结构组织最终并不为每个人的福祉而服务，它本质上只在乎三件事：

1. 维持自身稳定
2. 扩大自身边界
3. 和同类交流

所有人类，所有智能生命，猫狗，鸟类，哺乳动物，全部都至少有高于0的人性。
在未来组织应该会变成可解决的问题，无论此理论是否是对的。

另一方面虽然我是从LLM开始推理的，但到了最后我发现LLM消失了。
如果transformer不能成为我想象中的这个完美的“特征关联器”，那么它也有可能会消失。
理论似乎不存在根本性逻辑谬误，我使用LLM加速验证子论点，所有子论点均可证明证伪，但若要进行完整实验，哪怕是最小化的实验也必须构建出一个真正的AI。
这超出了我的个人能力，而子论点又无法支撑起全局。


